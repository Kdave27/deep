{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITGBsqzC5VIt"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  e_x = np.exp(x - np.max(x))\n",
        "  return e_x / e_x.sum()\n",
        "\n",
        "\n",
        "def softmax_derivative(x):\n",
        "  return softmax(x) * (1 - softmax(x))\n",
        "\n",
        "def ReLU(x):\n",
        "  return np.maximum(0, x)\n",
        "\n",
        "def ReLU_derivative(x):\n",
        "  x[x<=0] = 0\n",
        "  x[x>0] = 1\n",
        "  return x"
      ],
      "metadata": {
        "id": "04u2vk5S5X-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_squared_error(y_true, y_pred):\n",
        "  return np.mean((y_true-y_pred)**2)\n",
        "\n",
        "def cross_entropy(y_true, y_pred):\n",
        "  return -np.sum(y_true*np.log(y_pred))"
      ],
      "metadata": {
        "id": "Vg53NRoP5p_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=np.array([0.8,0.6,0.7])\n",
        "outputs=np.array([0,1,0])"
      ],
      "metadata": {
        "id": "GPOOSJDU5wVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "input_size=2\n",
        "hidden_size=1\n",
        "output_size=1"
      ],
      "metadata": {
        "id": "2LVOLudP61cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_input_hidden_w1=np.array([[0.2, 0.4, 0.1],\n",
        "                              [0.5, 0.3, 0.2],\n",
        "                              [0.3, 0.7, 0.8]])\n",
        "bias_hidden_b1=np.array([0.1, 0.2, 0.3])\n",
        "\n",
        "weight_hidden_output_w2=np.array([[0.6, 0.4, 0.5],\n",
        "                              [0.1, 0.2, 0.3],\n",
        "                              [0.3, 0.7, 0.2]])\n",
        "\n",
        "#weight_hidden_output=np.array([[0.4],\n",
        " ##                             [0.6]])\n",
        "bias_output_b2=np.array([0.1, 0.2, 0.3])"
      ],
      "metadata": {
        "id": "PmaH8KYK6-ON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=0.01\n",
        "epochs=10000"
      ],
      "metadata": {
        "id": "CZPn3UnQ9V4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  hidden_input_h1=np.dot(inputs,weight_input_hidden_w1)+bias_hidden_b1\n",
        "\n",
        "  hidden_output_a1=ReLU(hidden_input_h1)\n",
        "\n",
        "  final_input_h2=np.dot(hidden_output_a1,weight_hidden_output_w2)+bias_output_b2\n",
        "\n",
        "\n",
        "  final_output_a2=softmax(final_input_h2)\n",
        "\n",
        "  loss=cross_entropy(outputs,final_output_a2)\n",
        "\n",
        "  error_output=final_output_a2-outputs\n",
        "\n",
        "  dl_dw2=error_output*hidden_input_h1.T\n",
        "\n",
        "  dl_db2=error_output\n",
        "\n",
        "\n",
        "  w2_new=weight_hidden_output_w2-learning_rate*dl_dw2\n",
        "\n",
        "  dl_dw1=np.dot(error_output,weight_hidden_output_w2.T)*inputs\n",
        "\n",
        "  dl_db1=np.dot(error_output,weight_hidden_output_w2.T)\n",
        "\n",
        "  w1_new=weight_input_hidden_w1-learning_rate*dl_dw1\n",
        "\n",
        "\n",
        "  b1_new=bias_hidden_b1-learning_rate*dl_db1\n",
        "\n",
        "\n",
        "  b2_new=bias_output_b2-learning_rate*dl_db2\n",
        "\n",
        "  weight_input_hidden_w1=w1_new\n",
        "  bias_hidden_b1=b1_new\n",
        "  weight_hidden_output_w2=w2_new\n",
        "  bias_output_b2=b2_new\n",
        "  if(epoch+1)%1000==0:\n",
        "    print(f\"Epoch:{epoch+1}, Loss:{loss:.4f}\" )\n",
        "\n",
        "\n",
        "print(\"new_w1:\",w1_new)\n",
        "print(\"new_b1:\",b1_new)\n",
        "print(\"new_w2:\",w2_new)\n",
        "print(\"new_b2:\",b2_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaP_rp-h9bod",
        "outputId": "e5bc31e7-df31-493e-d6c6-b1d11fa4e166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1000, Loss:0.0061\n",
            "Epoch:2000, Loss:0.0026\n",
            "Epoch:3000, Loss:0.0016\n",
            "Epoch:4000, Loss:0.0011\n",
            "Epoch:5000, Loss:0.0009\n",
            "Epoch:6000, Loss:0.0007\n",
            "Epoch:7000, Loss:0.0006\n",
            "Epoch:8000, Loss:0.0005\n",
            "Epoch:9000, Loss:0.0004\n",
            "Epoch:10000, Loss:0.0004\n",
            "new_w1: [[0.37712267 0.58861309 0.50002325]\n",
            " [0.67712267 0.48861309 0.60002325]\n",
            " [0.47712267 0.88861309 1.20002325]]\n",
            "new_b1: [0.32140334 0.51435515 0.87146178]\n",
            "new_w2: [[ 0.30895303  1.22496567  0.0688959 ]\n",
            " [-0.19104697  1.02496567 -0.1311041 ]\n",
            " [ 0.00895303  1.52496567 -0.2311041 ]]\n",
            "new_b2: [-0.20983937  0.78343074  0.02640862]\n"
          ]
        }
      ]
    }
  ]
}